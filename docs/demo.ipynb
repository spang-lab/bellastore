{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bellastore Demo\n",
    "\n",
    "The purpose of this demo is to showcase the main functionality of this package.\n",
    "\n",
    "The main purpose of `bellastore` is to organize whole slide image scans (WSI, one of the main data sources in digital pathology) both on a filesystem as well as on a database level.\\\n",
    "Therefore, `bellastore` creates and manages a database with ingress and storage tables and moves valid WSI files from ingress to storage within the file system and records this within the databases.\n",
    "\n",
    "This ultimately leads to a comprehensive storage databse that can efficiently be queried in order to retrieve files from a storage containing possibly tens of thousands of WSIs.\n",
    "\n",
    "On the other hand the ingress database serves the purpose of recording the origin of the files.\\\n",
    "Often clinical labs encode valuable information in folder and file names which are directly recorded in the ingress database.\\\n",
    "Thus, even after moving and renaming at the storage level, all the original source metadata is tracked.\n",
    "\n",
    "Furthermore, the ingress serves the purpose of only allowing slides to the storage that are not already tracked.\\\n",
    "It still records a new possible duplicate in the ingress (as it could hold valuable metadata), but the WSI will not proceed to the storage.\\\n",
    "WSI identity is checked by hashing the scan file. For large scans this is the main time consuming point within the pipeline.\n",
    "\n",
    "The beauty of `bellastore` is that the storage database allows for being extended in the spirit of relational databses with all sorts of metadata, like patient identifiers, clinical grades, cohort identifiers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The philosophy of the `bellastore` backend is that it keeps track of the file system via the `Fs` class and keeps this in sync with the databases by the inheriting `Db` class.\n",
    "\n",
    "This demo showcases the workflow of `bellastore` by encapsulating the main integration test `tests/test_db_fs.py::test_classic`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a mock ingress and storage\n",
    "\n",
    "First of all we need to mock the state of the file system and the databases.\n",
    "\n",
    "In the main usecase of `bellastore` we are in the following scenario:\n",
    "- there are scans already recorded both in the ingress and storage databse\n",
    "- the respective scans are present in the storage file system\n",
    "\n",
    "In this demo we start from scratch and then in a second step mock a new cohort arriving from the clinic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from tempfile import TemporaryDirectory, TemporaryFile\n",
    "import shutil \n",
    "\n",
    "from bellastore.utils.scan import Scan\n",
    "from bellastore.database.db import Db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scans(path: Path, amount=4) -> List[Scan]:\n",
    "    '''\n",
    "    Mocks scans on a specified path.\n",
    "\n",
    "    The mock scans are just txt files containing content unique for each scan.\n",
    "    However they carry the file ending .ndpi \n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    path : Path\n",
    "        The shared directory holding the mocked scans\n",
    "    amount : int\n",
    "        The amount of scans to be created\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    List[Scans]\n",
    "        The list of created scans\n",
    "    '''\n",
    "    scans = []\n",
    "    for i in range(amount):\n",
    "        p = path / f\"scan_{i}.ndpi\"\n",
    "        p.write_text(f\"Content of scan_{i}.ndpi\", encoding=\"utf-8\")\n",
    "        scan = Scan(str(p))\n",
    "        scans.append(scan)\n",
    "    return scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the root of the fs holding both storage and ingress\n",
    "root_dir = TemporaryDirectory().name\n",
    "\n",
    "# create four scans in ingress\n",
    "ingress_dir = Path(root_dir) / \"new_scans\"\n",
    "os.makedirs(ingress_dir)\n",
    "ingress_scans = create_scans(path=ingress_dir, amount=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the database holding ingress and storage table\n",
    "db = Db(root_dir=root_dir, ingress_dir=ingress_dir, filename='scans.sqlite')\n",
    "# The first part of the output shows the fs tree, and the second shows the Ingress and Storage tables.\n",
    "# (Jupyter might out the tables as a single line)\n",
    "print(str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Db` class holds now all information of both the database as well as the file system.\n",
    "- there are 4 scans in the ingress (`new_scans`)\n",
    "- the storage contains only the database file `scans.sqlite`\n",
    "- the database holds two empty tables `Ingress` and `Storage`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert into storage\n",
    "\n",
    "Now it is time to insert the scans from the ingress into the storage.\n",
    "\n",
    "Note that this is a delicate process, requiring the following actions ðŸ’¡:\n",
    "- we need to check if the file in the ingress is a **valid** scan\n",
    "    - if not it will stay in the ingress as it is -> BREAK\n",
    "- **hash** the scan in order to make it comparable to existing scans\n",
    "- **compare** the hash to the already recorded hashes in the **ingress table**\n",
    "    - if there is an entry with identical hash, path and sanname, the file is removed from the fs -> BREAK\n",
    "- **compare** hash to the the already recorded hashes in the **storage table**\n",
    "    - if hash is already in storage table, record scan only in ingress table and then remove file from the fs -> BREAK\n",
    "- **add** scan to the **storage databse**\n",
    "    - move file into the storage directory\n",
    "    - record scan in the storage table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scans = db.insert_from_ingress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log message displays each state a slide follows according to the logic described above.\n",
    "\n",
    "Now we can check if the filesystem and the databse is actually in the state that we expect them to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage contains four hashed slides\n",
    "# ingress and storage table also hold exactly these slides\n",
    "print(str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now properly initialized our database and the filesystem now holds four scans ðŸ™Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new and existing scans to the storage\n",
    "\n",
    "In an application scenario, we will receive now a new cohort of scans. This batch might hold scans that are not present in the storage yet, as well as duplicates of the scans we already have.\n",
    "\n",
    "In the following example the *new* cohort, is just the old cohort extended by two new scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingress_dir = Path(root_dir) / \"new_cohort\"\n",
    "os.makedirs(ingress_dir)\n",
    "ingress_scans = create_scans(path=ingress_dir, amount=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inserting now from ingress, we expect that **all** scans of the new cohort will be recorded in the ingress table (because the folder name `new_cohort` is different to the previous folder name `new_scans` which might be valuable metadata that we definetly do not want to loose).\n",
    "\n",
    "However, we only expect `scan_4.ndpi` and `scan_5.ndpi` to be inserted into storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scans = db.insert_from_ingress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops, what happend? ðŸ¤”\n",
    "\n",
    "Well the filesystem and the database do not know that the ingress directory is no longer `new_scans` but `new_cohort`. So we need to first mount the new ingress directory.\n",
    "\n",
    "Note that this of course does not reinitialize the databse, as all scans are stored in `scans.sqlite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Db(root_dir=root_dir, ingress_dir=ingress_dir, filename='scans.sqlite')\n",
    "print(str(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scans = db.insert_from_ingress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the log we see: Everything worked out as expected. ðŸ”¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bell-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
